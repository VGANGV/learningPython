# 第一个python代码的读后感

## 库

库的安装：在终端中用`pip`或`brew`下载安装

在源代码中用`import`用来导入库。

`requests`库中的`get()`方法用来向后台请求数据，另外还有`post()`方法向后台提交数据。

## 变量

`meizi_headers`是各种操作系统的浏览器参数。（可能🤔是个字符串的数组？？）

全局变量`header`从`meizi_headers`中随机选取一个作为模拟的浏览器类型。

常量`mziTu`是要爬取的目标网站。

全局变量`save_path`是存储路径

## 函数

下面开始定义函数

可以看到python的函数定义格式是

```python
def functionName(paramName):
  
```

有函数名和参数名（**不同之处在于，没有指定参数的数据类型，也没有函数的返回类型**）

### createFile()

判断给定目录现在存不存在，存在就算了，不存在就创建，然后切换当前目录为新创建的目录。

这里能从os库的方法上看出Linux指令的影子，`makedirs`就是`mkdir`，`chdir`就是`cd`

### download()

`res_sub`使用requests库的get方法（第一个参数是URL，第二个参数前面加了‘headers=’，应该是告诉编译器这是浏览器型号吧）获取了目标网页的*HTML文档*。

`soup_sub`使用了神秘的`BeautifulSoup()`函数，看注释说是解析，具体意思不太懂，感觉上就是把一个生硬的一整块文档拆分成灵活的一个个标签吧。

`all_a`用了`soup_sub`的`select`方法，这个方法很好用，后面加上标签，从父标签名到子标签名，用空格隔开，每一级表签名后可以用[]筛选属性的某个特定值。具体这里的`select`方法是获取

```html
<a target="_blank" ...><img ...></a>
```

这里all_a是个数组，数组中的元素是一个个被筛选出来的`<img>`标签。

继续往下走，熟悉的foreach，在python里直接用for就行了，到这里才注意到整个原代码的{}的量和其他语言相比真的是太少了。

循环里加了个判定条件，count必须是偶数，只爬取每页中的偶数项图片？？

`<img>`标签的`src`属性就是图片的资源地址，代码中用`attrs['src']`方法获取了标签的指定属性。

下面是用同样的`requests.get()`获取了图片，把图片存进了变量`img`中。

用字符串的`split()`方法用字符'/'拆分成一段段字符串，放进数组`array`中，并获取倒数第一个值作为文件名。

`open()`函数是存储文件用的，第一个参数是文件名，第二个参数ab百度说是用于追加的，其他可选参数还挺多的，见到再记吧。

`write()`写入文件

`close()`写完后关闭文件（这个应该挺容易忘的，不关闭会怎样？？下次循环就不能再打开了吗？）

### main()

重复的不说了，

soup对象的find方法有点迷糊，筛选指定class的某种标签这里筛选的标签名是`<div>`，然后用find_all找到这些`<div>`中的`<a>`吗，这里find_all返回的是个数组，[-2]负数下标表示倒数第几个元素

.text取其值（对标签来说，text就是被标签夹住的文本）

有了总页数，下面就开始便利，第一页的URL和后面不一样，需要特殊处理。

下面就是用前面定义好的函数创建目录，然后下载文档。



最后是这个，应该不是重点，pycharm这一行左边能看到有个运行的符号，所以这里肯定是程序入口。

```
if __name__ == '__main__':
    main()
```
